{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c70fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from time import sleep\n",
    "\n",
    "# Things to try:\n",
    "# 1. What happens with a larger network?\n",
    "# 2. Better Normalization with BatchNorm\n",
    "# 3. Different learning rate (is there a better one?)\n",
    "# 4. Change architecture to a CNN => Tutorial #2\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 128), \n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 1), \n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, img_dim),  # 28x28x1 => 784\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "def img(img, e, i):\n",
    "    img = img.cpu().numpy()\n",
    "    plt.figure(figsize = (25,25))\n",
    "    plt.imshow(np.transpose(img, (1,2,0)), interpolation='nearest', cmap=\"gray\")\n",
    "    plt.savefig(f'image/e{e}-i{i}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Hyperparams etc.\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4\n",
    "z_dim = 64  # Try 128, 256, etc\n",
    "image_dim = 28 * 28 * 1  # H * W * C\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim, image_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "dataset = datasets.MNIST(root=\"./../_datasets/dataset/\", transform=transforms, download=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "step = 0\n",
    "\n",
    "# Train Loop\n",
    "with trange(num_epochs, unit=\"e\") as tepoch:\n",
    "    for epoch in tepoch:\n",
    "        for batch_idx, (real, _) in enumerate(loader):\n",
    "            real = real.view(-1, 784).to(device)\n",
    "            batch_size = real.shape[0]\n",
    "\n",
    "            # Train Discriminator\n",
    "            # Maximise log(D(real)) + log(1 - D(G(z))\n",
    "            noise = torch.randn(batch_size, z_dim).to(device)\n",
    "            fake = gen(noise)\n",
    "            disc_real = disc(real).view(-1)\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake).view(-1)\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "            # Train Generator \n",
    "            # Minimize min log(1 - D(G(z))) => max log(D(G(z)))\n",
    "            output = disc(fake).view(-1)\n",
    "            lossG = criterion(output, torch.ones_like(output))\n",
    "            gen.zero_grad()\n",
    "            lossG.backward()\n",
    "            opt_gen.step()\n",
    "            tepoch.set_postfix(lossD=lossD.item(),lossG=lossG.item())\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                    data = real.reshape(-1, 1, 28, 28)\n",
    "                    img_grid_fake = torchvision.utils.make_grid(fake, normalize=True, padding=5)\n",
    "                    img(img_grid_fake, epoch+1, batch_idx)\n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
